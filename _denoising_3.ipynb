{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cuda, optim, tensor, zeros_like\n",
    "from torch import device as torch_device\n",
    "from torch.nn import L1Loss, MSELoss\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from darts.common_utils import *\n",
    "from darts.phantom import generate_phantom, phantom_to_torch\n",
    "from darts.noises import add_selected_noise\n",
    "from darts.early_stop import EarlyStop, MSE, MAE\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch_device('cuda' if cuda.is_available() else \"cpu\")\n",
    "dtype = cuda.FloatTensor\n",
    "\n",
    "\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "                       in_channels=1, out_channels=1, init_features=64, pretrained=False)\n",
    "\n",
    "buffer_size = 100\n",
    "patience = 1000\n",
    "num_iter = 7500\n",
    "show_every = 1\n",
    "lr = 0.00005\n",
    "\n",
    "# reg_noise_std = 1./30. \n",
    "reg_noise_std = tensor(1./30.).type(dtype).to(device)\n",
    "noise_type = 'gaussian'\n",
    "noise_factor = 0.1\n",
    "resolution= 6\n",
    "n_channels = 1\n",
    "\n",
    "raw_img_np = generate_phantom(resolution=resolution) # 1x64x64 np array\n",
    "img_np = raw_img_np.copy() # 1x64x64 np array\n",
    "img_torch = torch.tensor(raw_img_np, dtype=torch.float32).unsqueeze(0) # 1x1x64x64 torch tensor\n",
    "img_noisy_torch = add_selected_noise(img_torch, noise_type=noise_type,noise_factor=noise_factor) # 1x1x64x64 torch tensor\n",
    "img_noisy_np = img_noisy_torch.squeeze(0).numpy() # 1x64x64 np array\n",
    "\n",
    "img_noisy_torch = img_noisy_torch.to(device)\n",
    "net_input = get_noise(input_depth=1, spatial_size=raw_img_np.shape[1], noise_type=noise_type).type(dtype).to(device)\n",
    "\n",
    "# Add synthetic noise\n",
    "net = model.to(device)\n",
    "net = net.type(dtype)\n",
    "\n",
    "# Loss\n",
    "criterion = MSELoss().type(dtype).to(device)\n",
    "\n",
    "# Optimizer\n",
    "p = get_params('net', net, net_input)  # network parameters to be optimized\n",
    "optimizer = optim.Adam(p, lr=lr)\n",
    "\n",
    "# Optimize\n",
    "\n",
    "loss_history = []\n",
    "psnr_history = []\n",
    "ssim_history = []\n",
    "variance_history = []\n",
    "x_axis = []\n",
    "earlystop = EarlyStop(size=buffer_size,patience=patience)\n",
    "def closure(iterator):\n",
    "    #DIP\n",
    "    net_input_perturbed = net_input + zeros_like(net_input).normal_(std=reg_noise_std)\n",
    "    r_img_torch = net(net_input_perturbed)\n",
    "    total_loss = criterion(r_img_torch, img_noisy_torch)\n",
    "    total_loss.backward()\n",
    "    loss_history.append(total_loss.item())\n",
    "    if iterator % show_every == 0:\n",
    "        # evaluate recovered image (PSNR, SSIM)\n",
    "        r_img_np = torch_to_np(r_img_torch)\n",
    "        psnr = skimage.metrics.peak_signal_noise_ratio(img_np, r_img_np)\n",
    "        temp_img_np = np.transpose(img_np,(1,2,0))\n",
    "        temp_r_img_np = np.transpose(r_img_np,(1,2,0))\n",
    "        data_range = temp_img_np.max() - temp_img_np.min()\n",
    "        if n_channels == 1:\n",
    "            multichannel = False\n",
    "        else:\n",
    "            multichannel = True\n",
    "        ssim = skimage.metrics.structural_similarity(temp_img_np, temp_r_img_np, multichannel=multichannel, win_size=7, channel_axis=-1, data_range=data_range)\n",
    "        psnr_history.append(psnr)\n",
    "        ssim_history.append(ssim)\n",
    "        \n",
    "        #variance hisotry\n",
    "        r_img_np = r_img_np.reshape(-1)\n",
    "        earlystop.update_img_collection(r_img_np)\n",
    "        img_collection = earlystop.get_img_collection()\n",
    "        if iterator % (show_every*10) == 0:\n",
    "            print(f'Iteration %05d    Loss %.4f' % (iterator, total_loss.item()) + '    PSNR %.4f' % (psnr) + '    SSIM %.4f' % (ssim) + '    Collection Size %.4f' % (int(len(img_collection))))\n",
    "        if len(img_collection) == buffer_size:\n",
    "            ave_img = np.mean(img_collection,axis = 0)\n",
    "            variance = []\n",
    "            for tmp in img_collection:\n",
    "                variance.append(MSE(ave_img, tmp))\n",
    "            cur_var = np.mean(variance)\n",
    "            cur_epoch = iterator\n",
    "            variance_history.append(cur_var)\n",
    "            x_axis.append(cur_epoch)\n",
    "            if earlystop.stop == False:\n",
    "                earlystop.stop = earlystop.check_stop(cur_var, cur_epoch)\n",
    "    if earlystop.stop:\n",
    "        return \"STOP\"\n",
    "    return total_loss\n",
    "    \n",
    "for iterator in range(num_iter):\n",
    "    optimizer.zero_grad()\n",
    "    early_stop = closure(iterator)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if iterator % (show_every*100) == 0:\n",
    "        r_img_np = torch_to_np(net(net_input))\n",
    "        plot_side_by_side(np.clip(img_np, 0, 1), np.clip(r_img_np, 0, 1), np.clip(img_noisy_np,0,1))\n",
    "\n",
    "    if early_stop == \"STOP\":\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "\n",
    "from torch import cuda, optim, tensor, zeros_like\n",
    "from torch import device as torch_device\n",
    "\n",
    "\n",
    "from darts.common_utils import *\n",
    "from darts.early_stop import EarlyStop, MSE, MAE\n",
    "from darts.noises import add_selected_noise\n",
    "from darts.phantom import generate_phantom, phantom_to_torch\n",
    "from darts.space import SearchSpace\n",
    "\n",
    "\n",
    "import nni\n",
    "import torch\n",
    "import nni.retiarii.strategy as strategy\n",
    "from nni.retiarii import model_wrapper\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from nni.experiment import Experiment\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(resolution, noise_type, noise_factor, input_img_np=None):\n",
    "    \"\"\"\n",
    "    Generates an image, adds noise, and converts it to both numpy and torch tensors.\n",
    "\n",
    "    Args:\n",
    "    - resolution (int): Resolution for the phantom image.\n",
    "    - noise_type (str): Type of noise to add.\n",
    "    - noise_factor (float): Noise factor.\n",
    "    - input_img_np (numpy.ndarray, optional): Input raw image in numpy format. If not provided, a new image will be generated.\n",
    "\n",
    "    Returns:\n",
    "    - img_np (numpy.ndarray): Original image in numpy format.\n",
    "    - img_noisy_np (numpy.ndarray): Noisy image in numpy format.\n",
    "    - img_torch (torch.Tensor): Original image in torch tensor format.\n",
    "    - img_noisy_torch (torch.Tensor): Noisy image in torch tensor format.\n",
    "    \"\"\"\n",
    "    if input_img_np is None:\n",
    "        raw_img_np = generate_phantom(resolution=resolution) # 1x64x64 np array\n",
    "    else:\n",
    "        raw_img_np = input_img_np.copy()\n",
    "        \n",
    "    img_np = raw_img_np.copy() # 1x64x64 np array\n",
    "    img_torch = torch.tensor(raw_img_np, dtype=torch.float32).unsqueeze(0) # 1x1x64x64 torch tensor\n",
    "    img_noisy_torch = add_selected_noise(img_torch, noise_type=noise_type, noise_factor=noise_factor) # 1x1x64x64 torch tensor\n",
    "    img_noisy_np = img_noisy_torch.squeeze(0).numpy() # 1x64x64 np array\n",
    "    \n",
    "    return img_np, img_noisy_np, img_torch, img_noisy_torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "#                        in_channels=1, out_channels=1, init_features=64, pretrained=False)\n",
    "\n",
    "def main_evaluation(model_cls):\n",
    "    device = torch_device('cuda' if cuda.is_available() else \"cpu\")\n",
    "    dtype = cuda.FloatTensor if cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "    buffer_size = 100\n",
    "    patience = 600\n",
    "    num_iter = 1200\n",
    "    show_every = 1\n",
    "    lr = 0.00005\n",
    "\n",
    "    reg_noise_std = tensor(1./30.).type(dtype).to(device)\n",
    "    noise_type = 'gaussian'\n",
    "    noise_factor = 0.1\n",
    "    resolution= 6\n",
    "    n_channels = 1\n",
    "\n",
    "    img_np, _, _, img_noisy_torch = preprocess_image(resolution, noise_type, noise_factor)\n",
    "    img_noisy_torch = img_noisy_torch.to(device)\n",
    "    net_input = get_noise(input_depth=1, spatial_size=img_np.shape[1], noise_type=noise_type).type(dtype).to(device)\n",
    "\n",
    "    # Add synthetic noise\n",
    "    net = model_cls().to(device)\n",
    "    net = net.type(dtype)\n",
    "\n",
    "    # Loss\n",
    "    criterion = nn.MSELoss().type(dtype).to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    p = get_params('net', net, net_input)  # network parameters to be optimized\n",
    "    optimizer = optim.Adam(p, lr=lr)\n",
    "\n",
    "    # Optimize\n",
    "\n",
    "    loss_history = []\n",
    "    psnr_history = []\n",
    "    ssim_history = []\n",
    "    variance_history = []\n",
    "    x_axis = []\n",
    "    earlystop = EarlyStop(size=buffer_size,patience=patience)\n",
    "    def closure(iterator):\n",
    "        #DIP\n",
    "        net_input_perturbed = net_input + zeros_like(net_input).normal_(std=reg_noise_std)\n",
    "        r_img_torch = net(net_input_perturbed)\n",
    "        total_loss = criterion(r_img_torch, img_noisy_torch)\n",
    "        total_loss.backward()\n",
    "        loss_history.append(total_loss.item())\n",
    "        if iterator % show_every == 0:\n",
    "            # evaluate recovered image (PSNR, SSIM)\n",
    "            r_img_np = torch_to_np(r_img_torch)\n",
    "            psnr = skimage.metrics.peak_signal_noise_ratio(img_np, r_img_np)\n",
    "            temp_img_np = np.transpose(img_np,(1,2,0))\n",
    "            temp_r_img_np = np.transpose(r_img_np,(1,2,0))\n",
    "            data_range = temp_img_np.max() - temp_img_np.min()\n",
    "            if n_channels == 1:\n",
    "                multichannel = False\n",
    "            else:\n",
    "                multichannel = True\n",
    "            ssim = skimage.metrics.structural_similarity(temp_img_np, temp_r_img_np, multichannel=multichannel, win_size=7, channel_axis=-1, data_range=data_range)\n",
    "            psnr_history.append(psnr)\n",
    "            ssim_history.append(ssim)\n",
    "            \n",
    "            #variance hisotry\n",
    "            r_img_np = r_img_np.reshape(-1)\n",
    "            earlystop.update_img_collection(r_img_np)\n",
    "            img_collection = earlystop.get_img_collection()\n",
    "            if iterator % (show_every*10) == 0:\n",
    "                print(f'Iteration %05d    Loss %.4f' % (iterator, total_loss.item()) + '    PSNR %.4f' % (psnr) + '    SSIM %.4f' % (ssim))\n",
    "                nni.report_intermediate_result(psnr)\n",
    "            if len(img_collection) == buffer_size:\n",
    "                ave_img = np.mean(img_collection,axis = 0)\n",
    "                variance = []\n",
    "                for tmp in img_collection:\n",
    "                    variance.append(MSE(ave_img, tmp))\n",
    "                cur_var = np.mean(variance)\n",
    "                cur_epoch = iterator\n",
    "                variance_history.append(cur_var)\n",
    "                x_axis.append(cur_epoch)\n",
    "                if earlystop.stop == False:\n",
    "                    earlystop.stop = earlystop.check_stop(cur_var, cur_epoch)\n",
    "        if earlystop.stop:\n",
    "            # Report final PSNR to NNI\n",
    "            nni.report_final_result(psnr)\n",
    "            return \"STOP\"\n",
    "        return total_loss, psnr\n",
    "        \n",
    "    for iterator in range(num_iter):\n",
    "        optimizer.zero_grad()\n",
    "        early_stop, psnr = closure(iterator)\n",
    "        optimizer.step()\n",
    "\n",
    "        if early_stop == \"STOP\":\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    \n",
    "    if earlystop.stop != \"STOP\":\n",
    "        nni.report_final_result(psnr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:07:07] \u001b[32mCreating experiment, Experiment ID: \u001b[36mej2c5i91\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:07:07,385 - INFO - Creating experiment, Experiment ID: ${CYAN}ej2c5i91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:07:07] \u001b[32mStarting web server...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:07:07,436 - INFO - Starting web server...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:07:08] \u001b[32mSetting up...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:07:08,541 - INFO - Setting up...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:07:08] \u001b[32mWeb portal URLs: \u001b[36mhttp://169.254.138.100:8081 http://169.254.67.161:8081 http://169.254.50.13:8081 http://10.0.0.172:8081 http://127.0.0.1:8081\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:07:08,719 - INFO - Web portal URLs: ${CYAN}http://169.254.138.100:8081 http://169.254.67.161:8081 http://169.254.50.13:8081 http://10.0.0.172:8081 http://127.0.0.1:8081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:07:08] \u001b[32mDispatcher started\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:07:08,806 - INFO - Dispatcher started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:07:08] \u001b[32mStart strategy...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:07:08,846 - INFO - Start strategy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:07:08] \u001b[32mSuccessfully update searchSpace.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:07:08,876 - INFO - Successfully update searchSpace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:07:08] \u001b[32mRandom search running in fixed size mode. Dedup: on.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:07:08,879 - INFO - Random search running in fixed size mode. Dedup: on.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:18:07] \u001b[32mStrategy exit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:18:07,552 - INFO - Strategy exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:18:07] \u001b[32mSearch process is done, the experiment is still alive, `stop()` can terminate the experiment.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:18:07,581 - INFO - Search process is done, the experiment is still alive, `stop()` can terminate the experiment.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# search space\n",
    "model_space = SearchSpace(in_channels=1, out_channels=1)\n",
    "evaluator = FunctionalEvaluator(main_evaluation)\n",
    "\n",
    "# search strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "exp_config.max_trial_number = 12   # spawn 50 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1 # will run 1 trial(s) concurrently\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:23:13] \u001b[32mConnect to port 8081 success, experiment id is ej2c5i91, status is DONE.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:23:13,127 - INFO - Connect to port 8081 success, experiment id is ej2c5i91, status is DONE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:23:13] \u001b[32mStopping experiment, please wait...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:23:13,129 - INFO - Stopping experiment, please wait...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:23:13] \u001b[32mExperiment stopped\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:23:13,162 - INFO - Experiment stopped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:23:13] \u001b[32mDispatcher exiting...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:23:13,168 - INFO - Dispatcher exiting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-15 22:23:15] \u001b[32mDispatcher terminiated\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 22:23:15,106 - INFO - Dispatcher terminiated\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
