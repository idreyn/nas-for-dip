{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Convolutions(nn.Module):\n",
    "    def __init__(self, conv, layer_name):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.LayerChoice(conv, label=f'{layer_name} - Step 2: Convolutions, Batchnorm and Activation')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class BaseBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseBlock, self).__init__()\n",
    "\n",
    "    def get_conv_ordered_dict(self, in_channels, out_channels, ks, pd, dl, activation):\n",
    "        layers = [\n",
    "            (\"Conv2d\", nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation,\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation\n",
    "                )\n",
    "            ),\n",
    "            (\"DepthwiseSeparable\", nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels, kernel_size=ks, padding=pd, dilation=dl, groups=in_channels),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation,\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl, groups=out_channels),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        return OrderedDict(layers)\n",
    "\n",
    "    def crop_tensor(self, target_tensor, tensor):\n",
    "        target_size = target_tensor.size()[2]  # Assuming height and width are same\n",
    "        tensor_size = tensor.size()[2]\n",
    "        delta = tensor_size - target_size\n",
    "        delta = delta // 2\n",
    "        return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n",
    "\n",
    "class EncoderBlock(BaseBlock):\n",
    "    def __init__(self, in_channels, out_channels, ks, pd, dl, activations, downsamples, layer_name):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.downsample = downsamples\n",
    "        self.conv_layer = Convolutions(self.get_conv_ordered_dict(in_channels, out_channels, ks, pd, dl, activations), layer_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        x = self.conv_layer(x)\n",
    "        return x\n",
    "\n",
    "class DecoderBlock(BaseBlock):\n",
    "    def __init__(self, in_channels, out_channels, ks, pd, dl, activations, upsamples, layer_name):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.upsample = upsamples\n",
    "        self.conv_layer = Convolutions(self.get_conv_ordered_dict(in_channels, out_channels, ks, pd, dl, activations), layer_name)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        upsampled = self.upsample(x)\n",
    "        cropped = self.crop_tensor(upsampled, skip)\n",
    "        return self.conv_layer(torch.cat([cropped, upsampled], 1))\n",
    "\n",
    "@model_wrapper\n",
    "class SearchSpace(BaseBlock):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "        ks = 5\n",
    "        dl = 3\n",
    "        pd = (ks - 1) * dl // 2\n",
    "\n",
    "        activation = nn.SiLU(inplace=True)\n",
    "\n",
    "        self.downsamples = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.upsamples = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "\n",
    "        # Conv layer in\"\n",
    "        self.mid_channels = 64\n",
    "        self.first = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.mid_channels, kernel_size=ks, padding=pd, dilation=dl),\n",
    "                nn.BatchNorm2d(self.mid_channels),\n",
    "                activation,\n",
    "                nn.Conv2d(self.mid_channels, self.mid_channels, kernel_size=ks, padding=pd, dilation=dl),\n",
    "                nn.BatchNorm2d(self.mid_channels),\n",
    "                activation\n",
    "                )\n",
    "\n",
    "        # Conv layer out\n",
    "        self.out = nn.Conv2d(self.mid_channels, out_channels, kernel_size=1, padding=0, dilation=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.first(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "import torch\n",
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "from darts.eval import main_evaluation\n",
    "\n",
    "from nni.experiment import Experiment\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:14:58] \u001b[32mDispatcher terminiated\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:14:58,685 - INFO - Dispatcher terminiated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:14:58] \u001b[32mCreating experiment, Experiment ID: \u001b[36mhnm0w49y\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:14:58,796 - INFO - Creating experiment, Experiment ID: ${CYAN}hnm0w49y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:14:58] \u001b[32mStarting web server...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:14:58,806 - INFO - Starting web server...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:14:59] \u001b[32mSetting up...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:14:59,891 - INFO - Setting up...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:15:00] \u001b[32mWeb portal URLs: \u001b[36mhttp://169.254.138.100:8081 http://169.254.67.161:8081 http://169.254.50.13:8081 http://10.0.0.172:8081 http://127.0.0.1:8081\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:15:00,023 - INFO - Web portal URLs: ${CYAN}http://169.254.138.100:8081 http://169.254.67.161:8081 http://169.254.50.13:8081 http://10.0.0.172:8081 http://127.0.0.1:8081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:15:00] \u001b[32mDispatcher started\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:15:00,040 - INFO - Dispatcher started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:15:00] \u001b[32mStart strategy...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:15:00,057 - INFO - Start strategy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:15:00] \u001b[32mSuccessfully update searchSpace.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:15:00,094 - INFO - Successfully update searchSpace.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Evaluator needs to be a lightning evaluator to make one-shot strategy work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m exp_config\u001b[39m.\u001b[39mtraining_service\u001b[39m.\u001b[39muse_active_gpu \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m# Execute\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m exp\u001b[39m.\u001b[39;49mrun(exp_config, \u001b[39m8081\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Public\\Public_envs\\pub_ml_env\\Lib\\site-packages\\nni\\nas\\experiment\\pytorch.py:306\u001b[0m, in \u001b[0;36mRetiariiExperiment.run\u001b[1;34m(self, config, port, debug)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe experiment mode \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is not supposed to invoke run() method.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 306\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_strategy(base_model_ir, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapplied_mutators)\n\u001b[0;32m    307\u001b[0m \u001b[39m# FIXME: move this logic to strategy with a new API provided by execution engine\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_completion()\n",
      "File \u001b[1;32mc:\\Users\\Public\\Public_envs\\pub_ml_env\\Lib\\site-packages\\nni\\nas\\experiment\\pytorch.py:214\u001b[0m, in \u001b[0;36mRetiariiExperiment._run_strategy\u001b[1;34m(self, base_model_ir, applied_mutators)\u001b[0m\n\u001b[0;32m    212\u001b[0m search_space \u001b[39m=\u001b[39m dry_run_for_formatted_search_space(base_model_ir, applied_mutators)\n\u001b[0;32m    213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_search_space(search_space)\n\u001b[1;32m--> 214\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mrun(base_model_ir, applied_mutators)\n\u001b[0;32m    215\u001b[0m _logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mStrategy exit\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Public\\Public_envs\\pub_ml_env\\Lib\\site-packages\\nni\\nas\\oneshot\\pytorch\\strategy.py:81\u001b[0m, in \u001b[0;36mOneShotStrategy.run\u001b[1;34m(self, base_model, applied_mutators)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mMutator is not empty. \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m _reason)\n\u001b[0;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(base_model\u001b[39m.\u001b[39mevaluator, Lightning):\n\u001b[1;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mEvaluator needs to be a lightning evaluator to make one-shot strategy work.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattach_model(base_model)\n\u001b[0;32m     84\u001b[0m evaluator: Lightning \u001b[39m=\u001b[39m base_model\u001b[39m.\u001b[39mevaluator\n",
      "\u001b[1;31mTypeError\u001b[0m: Evaluator needs to be a lightning evaluator to make one-shot strategy work."
     ]
    }
   ],
   "source": [
    "\n",
    "# search space\n",
    "model_space = SearchSpace()\n",
    "evaluator = FunctionalEvaluator(main_evaluation)\n",
    "\n",
    "# search strategy\n",
    "# search_strategy = strategy.Random(dedup=True)\n",
    "search_strategy = strategy.DARTS()\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "exp_config.max_trial_number = 12   # spawn 50 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1 # will run 1 trial(s) concurrently\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:17:16] \u001b[32mConnect to port 8081 success, experiment id is hnm0w49y, status is RUNNING.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:17:16,707 - INFO - Connect to port 8081 success, experiment id is hnm0w49y, status is RUNNING.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:17:16] \u001b[32mStopping experiment, please wait...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:17:16,708 - INFO - Stopping experiment, please wait...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:17:16] \u001b[32mExperiment stopped\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:17:16,729 - INFO - Experiment stopped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:17:16] \u001b[32mDispatcher exiting...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:17:16,737 - INFO - Dispatcher exiting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-16 18:17:18] \u001b[32mDispatcher terminiated\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:17:18,494 - INFO - Dispatcher terminiated\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
